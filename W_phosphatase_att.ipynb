{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "import seaborn as sns\r\n",
    "import scipy\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.utils import data\r\n",
    "from torch.nn.utils.weight_norm import weight_norm\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import roc_curve, auc\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import precision_recall_curve\r\n",
    "import attention_classification_v5\r\n",
    "from attention_classification_v5 import padding, CNN, Encoder, CNN_dataset, ATT_dataset\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (layers): EncoderLayer(\n",
       "    (enc_self_attn): MultiHeadAttentionwithonekey(\n",
       "      (W_Q): Linear(in_features=768, out_features=2048, bias=False)\n",
       "      (W_K): Linear(in_features=768, out_features=256, bias=False)\n",
       "      (W_V): Linear(in_features=768, out_features=2048, bias=False)\n",
       "      (fc): Linear(in_features=2048, out_features=1, bias=False)\n",
       "    )\n",
       "    (pos_ffn): PoswiseFeedForwardNet(\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=860, out_features=1024, bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder(d_model=768, d_k=256, n_heads=8, d_v=256, out_dim=1, max_len=604, sub_dim=256, d_ff=1024)\r\n",
    "model.double()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\r\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr=0.0001)\r\n",
    "critation = nn.MSELoss()\r\n",
    "scaler = torch.cuda.amp.GradScaler()\r\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_all_hidden', 'X_substrate_encoding', 'y_data'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = pickle.load( open( \"Y04E_all_X_y.p\", \"rb\" ) )\r\n",
    "embedding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(list(zip(embedding[\"X_all_hidden\"],embedding[\"X_substrate_encoding\"])), embedding[\"y_data\"], test_size=0.3, random_state=42)\r\n",
    "x_validation,x_test,y_validation,y_test = train_test_split(x_test,y_test,test_size=0.3333, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_train, x_sub_train = zip(*x_train)\r\n",
    "x_emb_validation, x_sub_validation = zip(*x_validation)\r\n",
    "x_emb_test, x_sub_test = zip(*x_test)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train = ATT_dataset(list(x_emb_train),list(x_sub_train),y_train,604)\r\n",
    "train_loader = data.DataLoader(emb_train,32,True,collate_fn=emb_train.collate_fn)\r\n",
    "emb_validation = ATT_dataset(list(x_emb_validation),list(x_sub_validation),y_validation,604)\r\n",
    "validation_loader = data.DataLoader(emb_validation,128,False,collate_fn=emb_validation.collate_fn)\r\n",
    "emb_test = ATT_dataset(list(x_emb_test),list(x_sub_test),y_test,604)\r\n",
    "test_loader = data.DataLoader(emb_test,128,False,collate_fn=emb_test.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15144/2599281335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m     14\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\software\\anacoda\\envs\\low_n\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\software\\anacoda\\envs\\low_n\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\software\\anacoda\\envs\\low_n\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):#1500\r\n",
    "    model.train()\r\n",
    "    for seq in train_loader:\r\n",
    "        enc_inputs, input_mask, substrate, target = seq[\"embedding\"], seq[\"mask\"], seq[\"substrate\"].double(), seq[\"target\"]\r\n",
    "        enc_inputs, input_mask, substrate, target = enc_inputs.cuda(), input_mask.cuda(), substrate.cuda(), target.cuda()\r\n",
    "        with torch.cuda.amp.autocast():\r\n",
    "            output, _ = model(enc_inputs, input_mask, substrate)\r\n",
    "            loss = critation(output,target.view(-1,1))\r\n",
    "        \"\"\"\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \"\"\"\r\n",
    "        scaler.scale(loss).backward()\r\n",
    "        scaler.step(optimizer)\r\n",
    "        scaler.update()\r\n",
    "    model.eval()\r\n",
    "    pre = []\r\n",
    "    gt = []\r\n",
    "    for seq in validation_loader:\r\n",
    "        enc_inputs, input_mask, substrate, target = seq[\"embedding\"], seq[\"mask\"], seq[\"substrate\"].double(), seq[\"target\"]\r\n",
    "        enc_inputs, input_mask, substrate = enc_inputs.cuda(), input_mask.cuda(), substrate.cuda()\r\n",
    "        with torch.no_grad():\r\n",
    "            output = model(enc_inputs, input_mask, substrate)\r\n",
    "        output = output.cpu().detach().numpy().reshape(-1)\r\n",
    "        target = target.numpy()\r\n",
    "        pre.append(output)\r\n",
    "        gt.append(target)\r\n",
    "    pre = np.concatenate(pre)\r\n",
    "    gt = np.concatenate(gt)\r\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(pre,gt)\r\n",
    "    print(\"epoch: {} | loss: {} | valiloss: {}\".format(epoch,loss,r_value))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e299e81cfa441c33efbdda2d7b49979e98d1419a05fc94ed236774d895656dab"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
